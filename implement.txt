Change the model$results function to do the following:
  1. Always generate a result list
  2. Result list should be a full R6 class with manipulation instructions
  3. Opening existing results should create a one-item list by default
  4. Individual results can be pulled out of the list for interrogation the old-fashioned way
  5. Model creates a list of results for selected stages
  6. Result object does not access data until we extract or export - it just locates results
  7. Default is to generate results for Reportable stages

Selection happens with an individual results (need to index into model$results().
  1. Re-implement selection as a list of G/T/N (rather than numeric indices)
     Problem with that is that it makes "cumulative" selection harder to pull off
  2. That way the selection can be "portable" across results
  3. Any field listed in a selection but not in the current results will just be ignored
     Or should it be forced to NA during extraction?

Need to consider unit conversion...

Then extracting is something we can do to a single result (wrap it in a list)
  1. We can manipulate the results in a result list to set selections
  2. Disable selections (by default) if extracting more than one result; function option to enable
  3. When extracting with a selection, change the metadata first (mark included/excluded)
  4. Extraction is a function of a result list, not an individual result

Extracting from a single result does one of two things:
  1. Return the result metadata (with selection marked, or optionally dropped): S/Y/G/T/N for all fields
     Scenario/Year/Group/Table/Name plus descriptors
  2. Return a data.frame for a selected G/T (columns include S/Y and all N)

At the level of a result list:
  1. Generate generate consolidated metadata for all individuals results in result list
     a. Respect selections in each individual result, if desired
     b. Can we apply one selection across all results - don't rush to implement selections....
     c. Selections are marked at the metadata level, then executed when metadata is used to pull out actual results data
     d. Includes literal ScenarioName and Year in block of metadata for each Scenario/Year
  2. Using consolidated metadata, develop ExportTable Names
     a. Include all Scenarios in one Table (or not - encode Scenario into table name)
     b. Include all Years in one Scenario Table (or not - encode Year into table name)
        Global Group has no years but may or may not be consolidated across scenarios
     c. Add S/Y to the metadata - then the S/Y/T name generation for ET can be done by processing each row
        Model Name and Export DateTime are part of the table name
        "%Table%_%Model%_%Scenario%_%Year%_ExportDateTime
        Generate a list of the relevant elements and join with "_"
     d. Assign ExportTable to each S/Y/G/T/N (iterate over metadata rows)
     a. Eliminate duplicate ET/G/T/N rows (ignoring S/Y - the ET name encoding will keep things separate as needed)
     b. Return a column specification set suitable for making CSV headers or defining an SQL/ODBC Table
  4. Export the data
     b. Build the ExportTable names and attach to each Metadata record based on Scenario/Year consolidation strategy
     a. Option to write the consolidated metadata to its own Table (include ExportTable field)
     c. Create each ExportTable in the output dataset based on its name and field descriptor
        1. Read the consolidated metadata for the list of ExportTables
        1. Generate set of column names and types for each ExportTable (no duplicates)
        2. CSV: write a header row
        3. SQL/DBI: create an empty table with suitable columns and no rows
           SQL types will be string, numeric/float, and perhaps integer - nothing complex
     d. Export data into ExportTable(s)
        1. Iterate selected Scenarios and within, iterate selected Years
        2. Iterate each Table within Scenario/Year
        2. Scenario + Year metadata is always guaranteed to be within a single ExportTable
        3. Get the ExportTable from metadata (error if more than one)
        4. Get the data.frame based on G/T/N present in metdata for this  
        2. Get data.frame using G/T/N for this Scenario/Year
        3. Append Scenario, Year as columns to data.frame
        4. Write data.frame to ExportTable

Extract a single result always produces the same thing:
  Scenario, Year
  Option - do not flatten (just report what is in the current stage)
  When building the index, should we keep track of the "SourceStage"?
  Then if we export just this one, we simply ignore any Stage != SourceStage
  See how the Datastore linkage is implemented...

The scheme above doesn't care how we nest scenarios and years - can just go through them in the
natural order (scenario, then group/year within) - and always just append that slice of the results
onto the given ExportTable.

For the export format, need to have these operations:
  Set "database" (place to write tables)
  Create an ExportTable with its name and Fields (from Metadata)
  Write a set of rows with compatible fields to the ExportTable

Then we just need to figure out how to realize it.
Parquet is neat since we can have individual tables but also have them viewable as a single unit.