The path to completion:

Verify that the WSDOT Scenarios are complete: they ran well as stages!

Get the scenario setup working, using addstage and building directories (and InputPath) as
needed.

Generalize addstage so it populates a modelstage without forcing it into the model's
RunParam_ls: we can specify where the ModelStages definition goes.

Basic scenario operation:
  Add scenarios to a model by creating ScenarioDir and adding ScenarioConfig file to it
    Helper functions to initialize ScenarioConfig
  If ScenarioDir (default="scenarios" relative to ModelDir) exists:
    - Add a key ScenarioConfig defaulting to "scenarios.cnf";
    - If it contains scenarios.cnf, that file will be opened and the keys "Categories" (optional)
      and "Scenarios" will be sought in it.
  The Scenarios key contains:
    ScenarioDir (where we look for the scenario stage definitions)
    StartFrom (the stage that the scenarios will start from; must be Reportable)
      - May be NULL (scenarios are free-standing runnable model stages)
      - Even without StartFrom, InputPath for Scenarios will still include InputPath
        for Model if the model has an InputPath
      - So the scenarios can still just have the subset of inputs that are different
    ModelStages (definitions of ModelStages)
      - Reportable will be ignored (always TRUE)
      - StartFrom can be specified (or NULL) for each ModelStage
      - The stage Config is always inline for Category-Level Scenarios
      - Free-standing scenarios can have a visioneval.cnf, which is read
        just as for standard model stages
  The Categories key (if present) contains:
    A list of categories (names)
    Within each categorie:
      Levels key (naming levels)
      Files key (naming input files that this Category varies)

The model's "$scenarios" function returns a VEModelScenarios object
  Pointer to the model
  StartFrom stage
  ScenarioDir (relative to model$modelPath)
  ModelStages (may be NULL)
Printing the scenarios object will say if scenarios are defined.
  VEModelScenarios$print()
    # Indicate type of scenarios (manual, category-based)
    # Indicate how many scenarios are defined
    # If manual, list the scenarios
    # If category-based report Category/Level/File, plus the number of generated scenarios
  VEModelScenarios$create()
    Does $load if ScenarioDir exists, otherwise create ScenarioDir and its visioneval.cnf
    Will set the StartFrom stage (required parameter)
  VEModelScenarios$load()
    Option to rewrite "StartFrom" if provided
    Will load "scenarios.cnf" if it exists in ScenarioDir and extract "Scenarios" key
    If "Scenarios" key does not exist, create it and resave scenarios.cnf
      Contains ScenarioDir, StartFrom
    Verify ModelStages if it is present
      Check that components of each given ModelStage are present and stage is runnable
  VEModelScenarios$files()
    Report the table of input files from StartFrom stage
    Perhaps report the Category (if any) to which the input file attaches
  VEModelScenarios$build()
    Reset = TRUE/FALSE; if TRUE, rewrite scenaros.cnf, if FALSE, just verify what is there
    Source = "folders" or "directories":'
      FileName, if present, is a vector of directories to make into scenario stages
        if not present, all sub-directories are made into stages
      Each designated sub-directory is made into a model stage (like any sub-directory)
      Populate the Scenarios structure (for scenarios.cnf)
      ModelStages will be just use the sub-directories as "StageDir" for the stages
      If the sub-directory has a visioneval.cnf, set StageConfig instead
      Names of sub-directories will be Names of scenario stages (must be unique relative to Model)
      Categories structure will not exist
    Source = "tables"
      Read FileName=scenario-categories.csv - a table of input files allocated to categories
      Can start with the list of input files from StartFrom stage
        There is a function to generate that
      Table has File, Category, Description
      Read scenario-levels.csv - a table of category levels
      Table has Category, Level, Description
      Create the Categories/Files/Levels structure (as in "config")
      Proceed to complete the build (below)
    Source = "config":
      Read FileName=visioneval.cnf and find a Categories structure that has these lists:
        Categories
          Files
            Must be inputs to StartFrom stage, must be unique across all Categories)
          Levels
            Sub-Folder for each Category-Level must exist
      Proceed to complete the build (below)
    Complete the build: After doing table or config build, complete as follows:
      Build a Categories/Files/Levels structure
      Validate categories:
        Each category must have at least one level (StartFrom is the base scenario for all)
        Each category must specify at least one file
        Each file from StartFrom input must exist in at most one category
      If Reset, blow away existing Category/Level folders and restock them
      Otherwise, only restock NEW Categories, Levels, Files
        Make folders for each Category
          Make folders for each Level
          Install the Category files into each Level folder
      In all cases, make Scenarios/ModelStage entry for each combination of Category-Level
         Set up InputPath (vector of Category-Level folders), Scenario, Description
         Goes straight into ModelStages (rewrite ModelStages structure)
    If reset or no scenarios.cnf, write resulting Scenarios and Categories tags into scenarios.cnf
    Otherwise, report discrepancies and instruct user to Reset

   # The ModelStages structure placed in the Model's Scenarios key:
   # Should end up defining:
   #   Name (of stage)
   #   Dir (compound name for stage, for ResultsDir)
   #   Scenario (==Stage Name; may not need if Name propagates to Dir)
   #   Description (Category + Level Descriptions): could end up REALLY long...
   #   InputPath (compounded as path to CategoryLevel subdirectories relative to
   #     ScenarioDir) - should normalize when Scenario stages are loaded.
   #   Reportable (always TRUE)
   #   Do we need any other configuration for the stage? More can just end up
   #   as extras in the Scenarios/ModelStages entry - don't do individual configs
   #     unless the stages have been defined manually

  Change ModelStage processing so the scenario stages are added in if ScenarioDir exists
    in the model and valid Scenarios are defined in its scenarios.cnf file.
  The base model is run first, then the scenarios are processed as a single group
    Scenario outputs are placed into ResultsDir, like regular stages
  That's a nice way to do it, since we can then just drop the "scenarios" directory into a
    base model without doing anything at all to its core configuration.xb

  Scenario stages are appended after the last regular ModelStage (note that the scenarios are
  automatically considered Reportable, and we don't alter Reportable for any "StartFrom" stage).
  Also require unique names for the scenarios. If scenario configuration is broken, just do a
  warning. Warn if model has no scenarios at all.

  Helper functions for VEModelScenario. Figure out how to interact these with the "build"
    function: probably these should just help make templates.
  VEModelScenarios$inputs(Filename="categories.csv") # Make the categories file a configurable parameter
    # return a data.frame of category, description, input files from StartFrom stage
    # if Filename provided, create that file (basename only) within ScenarioDir
    # if Filename exists, read it and merge its contents with StartFrom input files list, otherwise create it
    # Category and Description are empty strings unless present in file
  VEModelScenarios$categories(Categories=list of Categories/Levels/Files, writeTables=FALSE)
    # Report if using directory-based (manual) scenarios
    # Report the Categories key from Scenarios key, if present, else "No categories defined"
    # If categories.csv plus possibly levels.csv exist, populate with what is found there
    # Can replace categories from a list (which may contain Levels and Files elements)
    # writeTables==TRUE, write out categories.csv and levels.csv
  VEModelScenarios$list()
    # report a vector of the scenario names
    # works for both category-based and manual scenarios
    # Or should it report a vector of VEModelStages - the latter is more flexible
    #   and could support the internal operation of creating the group of scenarios
    #   to run.
    # Picking a "stage" for producing a directory or finding out about it should look
    #   not just into the model's intrinsic ModelStages but also into the Scenarios$ModelStages

  In the VEModel print function, treat scenario stages differently - acknowledge they exist and how
  many there are, details=TRUE will print the scenarios object.

  When the model is run, the scenarios just end up as stages in ResultsDir. Calling out the model
  results will find them and their definitions, which could be mashed into the top level model
  stages or kept as a separate list (appended implicitly to the end of the core ModelStages).

Process Management

Build a process controller for the model stages. To run the model, we create a queue of future
objects for each stage, with each one running a stage. +We can't start a stage until its "StartFrom"
is complete. So we'll group the stages by "StartFrom". We'll make a future running the stage into
each stage in the Group (we can start everybody in the group all at once); then we'll loop over
the group until all the elements are resolved.

Scan the list of stages to make groups:
  1. All stages, in order, with no "StartFrom"
  2. For each stage G in Group 1:
     All stages that StartFrom=="G"
  3. For each Group created in 2, do the same operation on any remaining ungrouped stages

The Groups are always run sequentially.
The individual stages in each group can run in parallel.
  If free workers > 0 add a future, otherwise poll ealier futures for resolved
    If resolved, then
      get the future's value (which should be the RunStatus) and put it in the Stage
      start the next future
    Otherwise, wait a second

The process runner can generate an offline status file as the processes it is polling finish and
new ones get started. That status file, which belongs to the model that the process runner is
processing, gets re-read when we ask for process status. That would ideally be a transactional
database... process runner does a polling loop on its processes to start N number of them, then
polls for finish and queue the next. It will also poll for presence of an updated request file. We
could just create a file system message queue (request/response) that uses files with standard
names and timestamps. So when we start running a model, we create the message queue directory (temp
directory) and send it to the process runner as a parameter. The process runner will poll for a
new file (written into under a temporary name, then renamed as an "almost atomic" operation) and
gather data to write into the response file (same timestamp as the request) - write the file under
a temp name, then rename it as an "almost atomic" operation. So we write the request, then go into
a loop waiting (up to a timeout) for the response file from the process runner.

Don't forget to manage the writeLog so when we do the run, the logging only goes to a file (not
the console).

Poll the r_process object for the run status. The results after the process is over (function
returns or fails) are backloaded into the model stage.

Need a simplified process status report (table) showing the Run Status for each stage, including
the low-level process status (so they can be cleaned up). Simple run management functions
(start/restart, stop, purge).

Create a "Waiting" status that is set into all the ModelStages for all the stages the model will
run. The ModelStages are grouped by their StartFrom (no StartFrom first). Then the process runner
will keep NUM_CORES processes running. When a process finishes, the next waiting in its group is set
in motion. When the group has all been set in motion and a core becomes free, the first waiting in
the next group is started. If any stage fails, the process runner does not add any additional
stages; all running ones will be allowed to complete/fail. Problems can be fixed, and a "continue"
run can be launched, which will set all incomplete stages to "Waiting" then start running them.

The process management does imply that we should have a single process runner that lives outside any
particular model. The model furnishes the list of stages to run and then calls the global
(singleton) process runner. That won't stop us from starting R twice, but it will let us trap
problems from having different models (or the same one!) running at the same time.

One way to manage that is not to allow any other model to run() until there are no more running
processes. Doing "running" will check if any model is running (it can be accessed via a model object
but also via a class function (VEModel$runner, for the process runner). That function will take a
command line option, and if none provided will show the running stages. We can ask for "waiting",
"complete", "failed", "running", or "paused" or some vector subset of those. We can also give a verb
plus PID to act on a particular process ("kill", "pause", "resume"). Default display: show
"complete", then "failed", then "waiting", then "running", then "paused". That is accomplished by
posing questions to the background process, which itself is in a loop to poll the processes.

Since the runner needs to be polling regularly (or using "future") to monitor the status of processes.

Organize Stages in the order of their StartFrom stage (no StartFrom are first). Queue the first group.
Then when a stage finishes, see if there is a group with 

Keep stages waiting if their StartFrom is not "Run Complete", and when a stage finishes, find any
later stages that StartFrom it and set all of those running.
  Run up to "max_child" processes - a runtime configuration item in VEModel, defaulting to 4.
  When a stage finishes, see if there are more queued for the current StartFrom

We can efficiently run the stages like this: Classify them as those that start from scratch and
those that StartFrom. Note that if there is a LoadModel/LoadStage directive, that is treated like a
"StartFrom", and we look back to see if that model/stage is available and has been run, then copy it
into the first model stage. All of that should happen prior to starting parallel processing (though
we could run the LoadModel if it is not RunComplete).
  1. Collect the "free" stages and run them in parallel (probably there will only be one).
  3. When ANY stage is complete, look down the list of stages for those that StartFrom the completed
     one's name. Set all those running.
  2. Move to the first "StartFrom" stage, and find all the other stages that start from the same
  place; those can run in parallel
  3.

Experiment with running a stage using 'callr': what do we need to construct in the separate R process
environment: all data/configuration elements present in the same location (all relative to ModelDir).
The RunParam_ls for the stage should be complete - build it and pass it to the child process.

Absorb Dan et al's scripts for extracting metrics...

Create the model visualizer (dump detailed structures to a JSON file, and then launch a static page
to navigate it). Visualizer should include the scripts, the configurations (including grayed-in defaults),
the module inputs and outputs. That can be a warmup for the full scenario viewer.

Create an option to the addstage function to make a stage in the file system (sub-directory within
the ModelDir), containing an (optional) Scripts directory, a visioneval.cnf (with the extras, and an
Inputs directory)
  - Create=TRUE (by default): look for/create StageDir if any Scripts/Inputs/Config are specified;
    can be forced to FALSE to leave everything only in memory. If we don't specific at least one of
    Scripts/Inputs/Config, the stage will take those from the Model - still need the Scenario specifiers
    like Scenario, Description.
  - Scripts=TRUE (by default): look for/create ScriptsDir in StageDir
  - Inputs=TRUE (by default): look for/create InputDir in StageDir; NA is like TRUE in forcing Create but does not
    make an InputDir sub-directory (expect just to drop the inputs into StageDir)
  - Config=TRUE (or filename): dump stage-specific parameters into filename/visioneval.cnf (otherwise leave
    them only in the ModelStage structure saved into the model). If they get saved to a file, remove
    the extras from the ModelStage, leaving only the Name, Dir, Config, Reportable etc. basic parameters.

If inputs have been developed elsewhere, option to provide a string of file paths (absolute) that
will be copied into the scenario stage directory.

So the VEScenario operation should go like this:
  - Identify a Base Model (an open VEModel) and copy it to the Scenario Model
  - Identify the ScenarioConfig configuration files describing the scenarios (see VEScenario)
  - Identify (or create) the "StartFrom" stage that is the basis for all the scenarios (e.g. "Future Year")
  - Generate a (possibly long) sequence of Reportable model stages that get written back out to the
    Scenario Model Copy's visioneval.cnf by iterating through the Scenario configurations. This uses
    "addstage" and will create directories with visioneval.cnf and inputs for each combined scenario.
  - Extend that mechanism to handle manually constructed scenarios (see Eric's scripts) - that's a tweak
    to the configuration file.
  - Using this scenario function, the stages are written to the model's config (just Name and Dir),
    but we also create directories with visioneval.cnf plus inputs. Those directories will be mirrored
    in results.

The "addstage" function should default to rewriting the ModelStages structure in the model's
visioneval.cnf. Could just do it in memory (leaving the residue in the ModelState_ls/RunParam_ls
results structure).

Add a metadata element ("Notes" structure) to visioneval.cnf that just contains an array of strings.
Later useful in the model inspector.

Set up scenarios using addstage function:
  1. Add a scenario to the model's runtime
     - Start From (base scenario)
  2. Rewrite the model stages description to the Model/Stage configuration (save it back out)
     A. Model gets Stage Configuration (stage does not get explicit configuration)
     B. Stage Configuration:
        - Path may not be set (it includes "Inputs" and "Scripts" if those vary for the scenario)
        - Config is not set in this case (but could be)
        - StartFrom (base scenario that other scenarios modify)
        - Dir (name of output subfolder for this scenario in ResultsDir)
        - Name
     C. Extra configuration parameters (also placed in ModelStages)
        - InputPath (one or more directories with scenario inputs)
        - Description
        - Reportable (defaults to TRUE)

Update the scenario viewer to be fully table driven.

If we open a VisionEval result set, we want to be able to patch in missing pieces if the run_model.R
was run using "source" on a script that includes initialize model. Can we open a model that was
"source'd", or must it have run in VE? Probably the latter, though it might be interesting to see if
openModel/VEModel$new can inject the missing information into the ModelState (run status, etc) by
reading the model and inspecting the results. Or we could suspend certain types of error checking if
the result artifacts are present (i.e. assume that Run Status is complete if the directory contains
what is needed).

Make sure queries and results give better errors if deployed on a model that has not yet been run.

Do a walkthrough for staged models (with scenarios, going all the way through to queries).

Check on query geography adjustment - can that really work?
Check on using Bzones as the geography level.
Check on doing all geographies (or a subset) rather than a single GeoValue

Does the H5 storage format still work?

Extract should work on a flat Datastore - I think we're doing that by flattenig the DatastoreListing.

Restructure Query output to use sub-folders.

Automate the debug dump. If we have a model that has crashed in a certain stage, we should be
able to open it, then do a crash exploration.

Get RunScript specified and working (to go with RunModule).

VEModel workflow:

Do ALL the tests (re-run every single model) and save the log results in a file for scrutiny.

In VEQuery, look at Brian's Bzone adjustments and allow Bzones to be a summary unit.
Let the Geography value be a list for summarizing.

Longer term: consider give a class to the ModelState_ls as well, so printing it
  will just show its names (and perhaps a summary of each item - the text itself
  if it's short, or a summary of long, multi-element items)

It would be great to develop a "debug dump" tool:
  Copy and zip the full model plus ResultsDir into a temp dir
  Zip the temp dir
  Send to some large file recipient address (could use SLFTS to receive)
    These outputs can get truly huge!
  Then there's a setup for a new model using the provided one:
    Copy the crashed model to a new model directory
    Adjust run_model.R to pick up where it crashed (from Log)
    Use LoadModel/LoadStage to identify model and stage for LoadDatastore
      Important to set LoadStage since it may have crashed in an earlier stage
      that was not reportable. The default is the previous model's final stage.
    Rewrite the run_model.R and the visioneval.cnf

Here's a slightly more elaborate approach
Steps:
  0. Open a model
  1. User supplies names of packages and modules
     User supplies name for the resulting model slice (default 'PostMortem')
  2. Default is last package/module listed in the log file listed before the [Error]
     Option to bundle an entire runnable model (plus the Datastore)
  4. Pull out just the group/table/name for that listed module(s)'s "Get" specifications.
  5. Make a new Datastore with DatastoreListing.Rda in a PostMortem directory
     That should result from flattening the Datastore (but filtering its contents by
     Group/Table/Name). Can use the Datastore copy operation but with a specific
     list of Datastore elements (new implementation).
  6. Include the ModelState_ls and the log file; include the "defs" directory and an
     inputs directory that only includes the "Inp" files for the package/modules.

On the other side, have an openPostMortem function that will build a mini-model to run
the module that may have crashed.
  0. Expand out into a PostMortem model.
  1. Create a run_model.R and a visioneval.cnf (dump the ModelState_ls$RunParam_ls)
     Make sure the directories map into the PostMortem model... (adjust many RunParam_ls
     entries like ParamPath, etc.).
  2. Put the inputs and defs directories in place.
  3. Do LoadDatastore=TRUE and set the path to the PostMortem Datastore directory
     Does the Datastore name have to include getRunParameter("DatastoreName")?
  4. Should have a runnable model with one stage that loads the PostMortem datastore
     and runs just the modules that were used to generate the PostMortem.

PostMortem need not be run on a failed model - it can be used to create a testbed for
any module, even if one that is working correctly.

Likewise with queries: resutsdir/outputs/query-timestamp/{queryspec,scenarios (results paths), output table}

Review Arash's scenario manager plus Eric Englin's additions.

#) Make several copies of the same base model with different years (only future) and different
   Model Name and Scenario Name.  Then check that we get good output from:
     List of model names
     List of model results
     List of model result directories
#) Add some specifications with the "By" option (income analysis, also by MArea or Azone, and by
   both. See how that shows up in the data.frame of results
#) Test running the same query set at different geographies
#) Think about the API for looking into a "scenario" root directory (where we might probe into
   sub-folders looking for VEResults based on existence of Datastore and ModelState.rda...).
   Eventually all that gets easier with the new VEScenario approach - we'll be able to require
   everything to have the same BaseModel, and a single master ResultsDir for the scenarios.

#) Explore running models in a separate space
   a) Launch an R process that we pre-load with objects from the current process
      Need visioneval, VEModel (full .libPaths); set working directory (ve.runtime)
      and then load/run a particular model. Need to make sure that the whole search
      path is properly constructed (including local environments) and that the
      runtime environment stuff stays loaded. What's the least we could do in a child
      process to make a model run (load VEModel, open the model, run it). Then when
      the process is done, reload the model state (as we currently do) in the front-end
      R session.
#) Get the scenario stuff integrated - very simple set of scenarios
   a) That will be the moment to change the Datastore access, which will need some
      careful thinking about how to initialize (bomb the model initialization if
      the base model has not been run, or should we recursively run the base model?).
      Specify the base model as a VEModel, or just by locating its ResultsDir (both).
   b) Future scenarios just run individual years, not the BaseYear. If there is no BaseModel
      run the BaseYear. Otherwise just run the other explicit years. Models with a BaseModel
      can but should not run the BaseYear.
   c) The key for the scenarios is not to run the BaseYear, which we can easily do just by
      leaving it out of Years.
   d) The BaseModel stuff initially should also encompass the RunScript, and load the
      BaseModel run parameters (so the derived model doesn't need to have any configuration
      other than the InputPath and ResultsDir). If we define Scenarios within the BaseModel
      then we'll just need a set of InputPath elements for each scenario category/level
      that we concatenate into a full set for the Scenario. So the tree could look like:
      /Base-Model
        /inputs
        /defs
        /results
        /queries
        /Scenarios
          /ScenarioName
            ... config files at the root
            ... config files specify category/level plus names
            ... config files also specify the .VEqry that will be applied to generate
                a comparative table of all the scenario results.
            /inputs
              /Category-Level folders with the input files
            /results
              /One subfolder for each permutation of category/level
              /outputs (for queries that run across the full set of results)
   e) Then do the visualizer base on what appears in the 

** Inspector

The inspectModel function should do a very simple interaction:
  1) We launch the HTML viewer, and point it at the page for the kind
     of thing being inspected
  2) Should be able to walk up or down the ladder
  3) Pass to Javascript should be a "Model" or "Collection" (Backbone concepts) with
     a particular name/processing type
  4) Stuff is available

Things we want to inspect:
  1) Settings
    a) Defaults
    b) Global (after ve.runtime)
  2) Models (model directory)
    a) List all models and inspect one
  3) Queries (query directory)
    a) List all queries (root) and inspect one
  4) One Model
    a) List all model stages and inspect one
    b) List all queries for Model (global, model-specific) and inspect one
    c) List Identifier, paths to all result sets for the Model
  5) One Model Stage
    a) Settings
    b) Input Directory (and files present)
    c) Param Dir (and files present)
    d) run_model.R script (raw text)
    e) initializeModel parameters (LoadDatastore)
    f) AllSpecs_ls (ordered sequence of Package/Module/Specs)
        Show Packages
        Within Packages expand to show Modules
        Within Modules expand to show Input, Get, Set specs
        Within a spec
          If Input, show InputDir, File, Group, Table
            Within InputDir,File show Fields, Units, Description
              Expand optionally to remining non-NA spec elements
          If Get/Set
            Show Group/Table
              Within Group, Table show Name, Units, Description
                Expand optionally to remaining non-NA spec elements
  6) One Query
    a) List of Query Specifications (names) and expression, pick one
    b) One Query Specification
       Full list of defined specification elements
