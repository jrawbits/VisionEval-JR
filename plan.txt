The path to completion:

display settings:
  Level:
    ve.runtime
    model
    stage
  Parameter Set:
    defaults (independent of level)
    constructed (RunParam_ls at that level)
    file (loadedParam_ls at that level, if present)
      Report parameters and full file path
  Modify loadedParam_ls and write back (make a .cnf.bak file from any existing)
  Modify the RunParam_ls in memory (to try something out)

Testing:
  Scenario/Stage input files changed (make sure correct file is read)
    Model parse should figure out where the input file would come from
    Listing out required/optional inputs from parsing run_model.R for the stage

VEModel workflow:

Need to be able to read/write/re-write configuration files. So perhaps an S3 class created
within the visioneval framework (to go with addParameters, etc).

For the model, save the configuration loaded from its file (for editing).
For the stage, save any configuration file loaded for it (for editing).
For both model and stage, overlay the configuration file parameters onto the runtime

Existing set of operations are the basis.
  Add an S3 class name to the parameter list
    Create a print function for that class (VEParameters)
    Use the presence of the class to determine what to do about the Source attribute
  Read a file
  Write a file
  Add/Modify paraneters
  Add source (converts bare list to VEParameters)
  Get a parameter
  Merge parameter lists (keep/override)

Do ALL the tests (re-run every single model) and save the log results in a file for
scrutiny.

In VEQuery, look at Brian's Bzone adjustments and allow Bzones to be a summary unit.
Let the Geography value be a list for summarizing.

Longer term: consider give a class to the ModelState_ls as well, so printing it
  will just show its names (and perhaps a summary of each item - the text itself
  if it's short, or a summary of long, multi-element items)

It would be great to develop a "debug dump" tool:
  Copy and zip the full model plus ResultsDir into a temp dir
  Zip the temp dir
  Send to some large file recipient address (could use SLFTS to receive)
    These outputs can get truly huge!
  Then there's a setup for a new model using the provided one:
    Copy the crashed model to a new model directory
    Adjust run_model.R to pick up where it crashed (from Log)
    Use LoadModel/LoadStage to identify model and stage for LoadDatastore
      Important to set LoadStage since it may have crashed in an earlier stage
      that was not reportable. The default is the previous model's final stage.
    Rewrite the run_model.R and the visioneval.cnf

Here's a slightly more elaborate approach
Steps:
  0. Open a model
  1. User supplies names of packages and modules
     User supplies name for the resulting model slice (default 'PostMortem')
  2. Default is last package/module listed in the log file listed before the [Error]
     Option to bundle an entire runnable model (plus the Datastore)
  4. Pull out just the group/table/name for that listed module(s)'s "Get" specifications.
  5. Make a new Datastore with DatastoreListing.Rda in a PostMortem directory
     That should result from flattening the Datastore (but filtering its contents by
     Group/Table/Name). Can use the Datastore copy operation but with a specific
     list of Datastore elements (new implementation).
  6. Include the ModelState_ls and the log file; include the "defs" directory and an
     inputs directory that only includes the "Inp" files for the package/modules.

On the other side, have an openPostMortem function that will build a mini-model to run
the module that may have crashed.
  0. Expand out into a PostMortem model.
  1. Create a run_model.R and a visioneval.cnf (dump the ModelState_ls$RunParam_ls)
     Make sure the directories map into the PostMortem model... (adjust many RunParam_ls
     entries like ParamPath, etc.).
  2. Put the inputs and defs directories in place.
  3. Do LoadDatastore=TRUE and set the path to the PostMortem Datastore directory
     Does the Datastore name have to include getRunParameter("DatastoreName")?
  4. Should have a runnable model with one stage that loads the PostMortem datastore
     and runs just the modules that were used to generate the PostMortem.

PostMortem need not be run on a failed model - it can be used to create a testbed for
any module, even if one that is working correctly.

Add a helper function for VEModel, which is "openResults" (taking a model name, or a path to a
results directory, defaulting to the current directory).

VEModel$results will generate VEResults from all its reportable stages (or specific names can be
supplied).

Opening a path fills in a VEResults. A list of paths makes a list of VEResults (if valid).

Could still keep the VEResults as it is now, and inject it as an element of the ModelStage.
So a VEModel contains one or more ModelStages, one or more of which are Runnable, and one or
more of which are Reportable. A runnable model stage builds a VEResults object when it is run
(plus the actual run results in the file system). A query works on a list of VEResults objects
(as it does currently), and gives back a list of vectors of metrics. It can also query a single
VEResult object.

Can VEResults itself always be a list of results? Perhaps what we really need to do is create
a VEModelStage class that will accumulate the results, and what we really get in VEResults is a list
of the stages. Then we have the path, the ModelState_ls and everything else we need, already open.
If we open a path from the file system, we find the ModelState_ls and expand that into a
VEModelStage object.

VEQuery will take a list of VEResults and operate on those. If we give it a VEModel, it pulls out
the Reportable stages (unless a specific stage is named: only one in that case, especially if not
Reportable) and builds a list of their results. Then we run the low-level query on each VEResults
and assemble a named list of query results (e.g. via lapply) and readily convert that list into a
data.frame.

Need to work on extract function: resultsdir/output/extract-timestamp/stage/{metadata.csv,results.csv}.
  Flatten or not to flatten? Answer is "flatten" so all available data shows up in the .csv, but option not to Flatten
Need to be able to re-read metadata.csv and do the same extract again.

Likewise with queries: resutsdir/outputs/query-timestamp/{queryspec,scenarios (results paths), output table}

Can now open a new-style model successfully (single stage VERSPM)
  Test loading the multi-stage standard models (All stages present and runnable? Correct reportable?)
    VERSPM-pop
    VERSPM-years
    VE-State-base
    VE-State-staged
    VERPAT
  Test that we can open a "classic" VERSPM (from sources/models)
  Test that we can open VE-Stage-staged (from sources/models)

Then go to work on making each model run: 

Functions to work out in VEModel:
  "addBaseModel"
    To copy over structural parameters from another model (probably near done)
  standard models
    Make them complete new-style models (versus the classic ones distributed)
  "ve.model.copy" copyResults (or not)
    Takes a snapshot of the Model without Results
    Note that VEResults should have a "copy" function to copy/flatten results (keeping
      the RunPath consistent so we can find stuff...
  "ve.model.rename"
    The use case was for altering model descriptors in a model copy
    May not need that any more. Need a deeper ability to edit model or stage settings
  "ve.model.loadModelState"
    Reimplement this just to open or create model states for each model stage
    Called automatically before "run" if model state is not on disk (based on
      save/continue/reset instruction)
  "ve.model.set"
    Inspect parameters for the model, or for a particular stage
    Need to indicate which stage to show (or the overall model)
    Perhaps need to simplify
  "ve.model.list"
    This should describe model/module inputs, outputs, things in the Datastore
    Uses summarizeSpecs function to generate the database
    Should return results for each stage separately (must ask for a stage)
    if we have linked stages (e.g. StartFrom) it should compile specs for the
      entire set of earlier stages
  "Stages"
    Need some functions to explore and navigate model stages
    We get a modelStage description and can inspect it in various ways
      (e.g. a modelStage is just a model...)
    Need to print, get results, etc.
  "ve.model.save"
    Part of the function set to edit and save model configurations
  "ve.model.run"
    Can be dramatically simplified - just runs the separate stages after
    loading them, using framework functions
  "ve.model.log"
    Report the log file for a stage (not just the final one).
  "ve.model.dir"
    This one may work, but needs to be properly updated for Stages
  "ve.model.clear"
    This one may work, but should be updated for stage structure...
  "ve.model.print"
    Needs better options and more descriptive elements
  "ve.model.resultspath"
    Update for model stages...
  "ve.model.results"
    Update to get results objects
    Needs particular work for "StartFrom" models (to keep the results all
      lined up).
  "ve.model.query"
    Update to get query objects (list) or to open one

Continue working to get VEModel running
  Initially, don't look for stages - just create the ModelDir as first stage
    So it will run a simple, classic model
    Opening the model builds its RunParam_ls structure.
    Loading the model will open or create the ModelState_ls in the model's ResultsDir
    Running the model will save/reset the Results
  Skip initializeModel if ModelState is present and a runtime flag is set ("InitComplete")
    New style model run from VEModel does not need initializeModel in the run_model.R script
    Probably need some back-stopping in RunModule and RunScript to ensure the ModelState and
      Datastore are ready for action.
  Load, Save and Run operations are disaggregated into VEModel
    Save/archiveResults does the same step as inside initalizeModel (after Load, before Run)
    Load visits the stages and expands a ModelState from the configurated RunParam_ls
      Parses all the specifications
    Run will build the Datastore and process the run_model.R script
  Verify other functions like "dir", "clear", "archive", "results", etc.
    Will need to review the VEModel R6 structure
  First approach to stages is to make sure we can run the old-style staged models (using
    LoadDatastore, and treating each stage essentially as a distinct model, placing its
    results in ResultsDir/StageDir)

Expand VEModel to run stages
  Consider BaseModel as a way of reaching outside the current model structure
    Essentially an automatic way to do LoadDatastore/LoadDatastoreName with a local
    run_model.R, inputs, etc - elements of the BaseModel can be used or discarded.
    A "pure" BaseModel supplies everything except ModelDir (which is used to update
    the RunDir). We can add additional stages on to that afterwards...
  "StartFrom" stage directive (or "BuildOn" or perhaps "BaseStage").
    Could create "StartFrom" and "EndAt" run arguments to use stage names/positions
  Need a "stages" command for VEModel to list and explore the stages
    Option on "print" to list out all stages (otherwise just their names)
    Separate commend to enumerate the stages and their relationship
      Stage directory, Run Status, StartFrom, Load/Linked
  VEModel sets up parameters from configuration - finding model stages

Runtime Setup (in VEModel)
  Locate run parameters as follows:
    ve.runtime (loaded from visioneval.cnf in that directory) (ve.env$RunParam_ls)
      DatastoreType
      QueryDir
      ParamDir
    ModelDir (loaded from visioneval.cnf in that directory)
      if BaseModel provided, load BaseModel elements from BaseModelStage
        BaseModel information accessed later by VEModel
          Base$QueryPath <- Base$ModelDir/Base$QueryDir
        Runtime File Locations that replace local path
          Base$InputPath
          Base$ModelScriptPath
          Base$RunDstore (transformed to LoadDstore if loading)
          Best$ParamPath
      Rebuild locations always:
        ModelDir (default is ".")
        ResultsDir (default is "results" inside ".")
      Possibly set:
        QueryDir (will read/write there, plus do read-only Base$ModelDir/Base$QueryDir, plus do read-only ve.runtime/QueryDir)
        Seed
        DatastoreType
        DatastoreName (not recommended)
        ParamDir
        ScriptsDir
        ModelScript
      Rebuild locations optionally
        ParamDir (if defined in this folder -> rebuild ParamPath)
        InputPath (if defined to anything here or undefined anywhere -> reset to character(0))
        ModelScriptPath (if ScriptsDir defined here or if ModelScriptPath is undefined)
          Set to script root if ModelScript undefined or does not exist in this directory: ModelDir/ScriptsDir
          Otherwise set to ModelDir/ScriptsDir/ModelScript (may still be overridden in stages)
          May add ModelScript from individual stage below (referring into this path)
      Add ModelDir to InputPath, if InputDir is present in ModelDir
        Remove from InputPath any directory that is not present or does not have InputDir in it
      Examine run_parameters.json for missing stuff
        Model
        Scenario
        Description
        Region
        BaseYear
        Years
        DatastoreName
        DatastoreType
        Seed
      Must have set after processing run_parameters.json (Years is optional; must be set to make a stage)
        Model (name; default is basename(ModelDir))
        Scenario (name; default is Model)
        Description (name; default is Scenario)
        Region
        BaseYear
        DatastoreName
        DatastoreType
        Seed
      ModelStages
        if defined, each named element uses name for sub-directory
          The components of named element are RunParam_ls for the stage
          Alternatively, each stage sub-directory can include a visioneval.cnf
        When building:
          Stage is complete if:
            ParamPath, InputPath, ModelScriptPath are available (defined and exist)
            Definition exists for Model, Scenario, Description, BaseYear
            Definition exists for Years
        If ModelStages is defined in the ModelDir, only set those up (error if any is incomplete)
          Can explicitly define a ModelStage with name of "."
            (which becomes "BaseStage" when we create a Results sub-directory.
          All the remaining stages would be sub-directories.
        If ModelStages is undefined
          Examine non-structural sub-directories within ModelDir
          StageDir is the subdirectory name
          Skip QueryDir, InputDir, ParamDir, ResultsDir, Any directory matching the archive template
          Make an entry for each sub-directory located
        For each ModelStage (regardless of how it was located):
          Examine the StartFrom parameter and construct DatastorePath for this Stage
          Read its visioneval.cnf for the following (only supply missing compared to explicit ModelStages definition)
            InputDir
            ScriptDir
            ModelScript
            Years (must define in ModelStages or visioneval.cnf)
            Scenario (force to StageDir if not explicit in ModelStates/visioneval.cnf for stage)
            Description (force to Scenario, if not explicit in ModelStates/visioneval.cnf for stage)
          Attempt to add ModelDir/StageDir/InputDir to InputPath (if it exists)
          Attempt to override ModelScriptPath with ModelDir/StageDir/ScriptDir/ModelScript (if it exists)
          Check for definition of BaseYear, Region, Model, Years, Scenario, Description
              
Model State Components:
  Cached Parameters
    RunParam_ls (used to build the ModelState; includes source information)
  Descriptive Information
    Model
    Region
    Scenario
    Description
    BaseYear
    Years
  Runtime File System Locations (all are absolute paths)
    BaseModel [Full path to BaseModel ModelDir]
    ModelDir [Root path for model to which this model state belongs; classic="."]
    RunDirectory [Composed from ResultsDir/StageDir; classic="."]
    ModelScriptPath [Absolute Path to script that build this ModelState; classic="./run_model.R"]
    ModelStatePath [Where this ModelState was built (could be copied later; not updated)]
    ParamPath [Absolute Path Version of what is in RunParam_ls; classic="./defs"]
    InputPath [Absolute Path Version of what is in RunParam_ls; a vector; classic="RunDirectory"]
    RunDstore [Name (path), Dir, File (basename)]
    LoadDstore [Name (path), Dir, File (basename)]
  Cached Structures
    AllSpecs_ls
    ParsedScript
    ModulesByPackage_df
    DatasetsByPackage_df
  Loaded versions of structure [At runtime]
    Geo
    Units
    Deflators
    BzoneSpecified
    CzoneSpecified
  Run Results
    Datastore [Datastore index; same as Datastore/DatastoreListing.Rda]
    LogFile [Name of log file associated with run]
    ModelStart [Timestamp built into LogFile name; happens at start of "Run"]
    FirstCreated [TimeStamp when ModelState was Initialized; might happen during "Load"]
    LastChanged [TimeStamp updated with every call to setModelState]
    RunStatus [Text code showing 
  Environmental Structure
    DatastoreType
    Seed
    DatastoreName

Do the following:
  Implement the ModelStages structure (replaces old ModelState and stagePaths)
    Name = how to refer to the Stage
    Report = TRUE/FALSE   # "terminal" stages by default; if TRUE, include in queries and extract
    Directory = StageDir (sub-directory of ModelDir for input, of ResultsDir for output, of Extract/<Date>/ for Extract or Query)
    ModelState = the cached ModelState for the stage (can go straight to "Run" with this)
  Find a Model
    Iterate through ModelDir and stages, loading complete configuration
    Verify completeness and add ModelStage list element (all but ModelState)
    Recognize intermediate and terminal stages
    Process the ModelStages configuration (if explicit)
  Archive ModelState and Results (SaveDatastore)
    Only archive if Datastore/Log is done
    Could force saving last ModelState build (but why?)
    Archive before rebuilding if requested
  Load a Model
    Cache all the ModelState elements
    Flag to not load ModelState (or not follow full BaseModel chain)
    Save the cached ModelState (or blow it away for rebuild)
  Run a Model
    Use the saved ModelState to run (don't re-initialize by default)
    Sub-function to eliminate/reset "run parts" (e.g. Datastore index) if model is re-running from a model state
    Supply pre-built model state (shuffle into ve.model environment)
    Constructs the Datastore and starts the log file
  Execute the run_model.R script
    Ignore initializeModel if Model is already set up (model state/Datastore/Logfile)
    Is there a ModelState in ve.model? Or have some runtime flag to use cached ModelState?
  Make sure we can build the index/inputs/list elements before the model is run
    Should that still be part of the results? Yes.
  Get the extract to work with stages
    Extract requested stages
  Get the queries to run across a set of stages in a model (only)
    Query always works with one model (not a set of them).
    Just iterate across the terminal stages.
    Open a parent directory as a "model"
      Queries/Extracts go in outputs at that level, even if there is nothing else set up as a Model there
  Re-do
    Model Copying
    Model Print
    Model Directory
    Model List
    Model Clear (include cached model state)
    Model Archive (new - runs the archive function on any results/model state present)
    Model Set (edit model configuration)
    Model Save (save model configuration updates)
    Model Results (get results object)
    Model Query (get query object)
  Implement the BaseModel approach
    Virtual Datastores
    Flatten Datastore (variation of extract - walks the child model ModelState_ls$Datastore)
      Archive previous Datastore, recreate locally
      If we copy a model with Datastore results (and include the outputs) it should flatten the results
        rather than just copying what is there verbatim (flag to control)
    Identify ModelStages
  

Now for the BaseModel:

  LoadDatastore is incompatible with BaseModel (it's one or the other). If BaseModel is specified,
  we ignore LoadDatastore. LoadDatastore makes things magically appear in the current Datastore. If
  the Loaded Datastore has BaseModel, etc., we should force it to be flattened before copying it over.
  Look at how the copy is done (might be brute force) and perhaps copy the fields by reading then
  rewriting them (much slower - incorporates flattening in the process).

  BaseModel implies linking an entire other model, not just pre-loading the Datastore. The latter is
  very useful for debugging.

  We want to create a full index in the ModelState that is the Datastore directory. We add a field
  to it that says which physical DstoreDir we will access to get it. We consult that when we try
  to read a Dataset. We also use that table to get Group/Table/Name. The list that is saved out
  to the disk just includes what is actually in the current Datastore (no BaseModel)

  So when we load a BaseModel, we just include its Datastore directory, and update all its "current"
  DstoreDir entries with the BaseModel's ResultsDir. Then we'll add the new model to it.

  The Datastore directory file only exists for a completed model.

  Parsing the run_model.R should happen separately from running the model. The resulting structure
  is the one we should interrogate for the model inputs and outputs. Perhaps that would be the
  end result of "SimulateRun" - it creates the list of all the fields we encountered, without
  actually building the Datastore.

  We can "flatten" or "realize" a virtualized Datastore for the current model and its results.
  That copies in all the BaseModel data (walks the chain), rewrites the Datastore index on disk,
  and updates the Datastore directory in the finished ModelState. The output of all that should
  not rewrite ResultsDir itself (or perhaps we *archive* ResultsDir before rewriting it).

ModelDir for each model is absolute root of its components
A model is defined by its RunParam_ls structure (amplified into its ModelState).
We can start a model from RunParam_ls, so that is what we store in the modelStages.
modelStages is a named list (it is kept in RunParam_ls)
  Each element is a modelStage
  Name is the path to the Stage (relative to ModelDir for model to which modelStages belongs)
A modelStage is a named list.
  RunParam_ls: Complete set of model settings
    BaseModel is absolute or relative (to embracing ModelDir)
    StageDir, if present, is relative directory (to embracing ModelDir)
    ModelDir is file.path(embracing$ModelDir,StageDir) or absolute (if not a subdirectory of current model)
  ModelState_ls: The model state (in memory, or loaded from disk if present)
    Contains a copy of RunParam_ls
    Contains model status (used during RunModel)

When we run the model, we just set up that environment, change to ModelDir/ResultsDir
and then source the ModelScript.

Two steps for initializeModel():
  LoadModel which sets up RunParam_ls and ModelState
  RunModel which archives past run and initializes Datastore

Essentially, we have to load its effective configuration (which we can get from
its ModelState_ls if it has been run, otherwise we need to explore
the BaseModel recursively first (we use the effective configuration of its
final ModelStage). The BaseModel run_model.R gets overwritten by the local
run_model.R if any. The BaseModel InputPath becomes the basis for the current
model's InputPath (accessed after the current model).

The current model is NOT allowed to override any of the BaseModel ParamDir
contents.

To find a model:
  At top level, set the VEModel$modelPath (different from runtime ModelDir
    that each stage gets)

  Load "effective configuration" for a directory
    locate directory from openModel/new/initialize
    set ModelDir in RunParam_ls
    read visioneval.cnf
    If there is a BaseModel, get its "effective configuration" as a basis
    Add ModelDir to InputPath (If present in visioneval.cnf, use that instead).
    InputPath should be a normalized list of after we load it
    Unpack the BaseModel
    This effective configuration may or may not end up as a ModelStage (see next test)

"Explore a directory" means to load the effective configuration and then see if it
has everythign to be a model.

Determine what directories and sub-directories to explore:
  If ModelStages is explicit for the current directory
    Explore only the listed directories
    Return a named list of RunParam_ls objects, one for each ModelStage found
      name of list item is directory (absolute or relative to initial ModelDir)
  Else explore the current directory
    If current directory IS a Model
      add current RunParam_ls (with its ModelDir)
    else (NOT a Model):
      Explore all the sub-directories that are not already identified as structural
        Structural Directories: InputDir, ParamDir, ResultsDir, QueryDir

Iterate over list of directories to explore:
  
Iterate over ModelStates

  Within that directory:
    look for InputPath/InputDir (anywhere on InputPath)
    look for ParamDir, if found read run_parameters.json and fill in the blanks
    locate ScriptDir/run_model.R
    read just the arguments from initializeModel (if present in run_model.R)
      (To capture anything set in the script)
    [TODO: need a framework function, called within initialize, to add build RunParam_ls]
  Return assembled RunParam_ls

Check if RunParam_ls is runnable:
  Can locate defs / inputs / run_model.R
  Has required elements for initiating ModelState (Name, Scenario, Desription)

If runnable:
  Add to end of self$modelStages

  Sub-directories will also be investigated if they are not "structural"
    That would let us build scenarios within a base model.
  Resurrect the StageDir parameter to identify a home for stage sub-directories

  Visit each subdirectory as a candidate ModelStage
    Add (temporarily) InputPath
    look for InputPath/InputDir (anywhere on InputPath) (if present)
    read visioneval.cnf (if present)
    look for ParamDir, if found read run_parameters.json and fill in the blanks (if present)
    locate ScriptDir/run_model.R (if present)
    if model is complete, store at end of ModelStage list
    Make a note of the BaseModel (in the ModelStage list structure)
    otherwise skip directory
  We have found a model if all of  defs / inputs / run_model.R can be located
    (May fail later on missing input files...)

Right after finding a model, we should "open"/"load" / "initialize" its model state, using the run
parameters we found (and checking presence of ResultsDir).

Seeking a BaseModel:
  name is an absolute path (living in space somewhere...)
  name is a Model Stage Name already in ModelStages (if found, that other model stage is NOT terminal)
  name is a directory in ModelPath (i.e. another model - that's a variation of "absolute path"

Do we want to consider making the BaseModel a "pre-requisite" (so we can't run this model if the
BaseModel is not complete).

The ModelStage structure should be sufficient to run the stage (that is, with such a structure as a
single parameter).

ModelStage structure wants to examine whether a ModelStage is a base model for another
stage (and flag it): we won't visit the base models during a query - just the ones
that are nobody else's base. Need to know:
  Model Path (relative to ModelDir or absolute)
  Model Stage Name (basename of its stage directory)
  BaseModel (if local, a Model Stage Name from this list; if not local, the absolute path)
  Is Terminal? If no other stage in the model uses it as a base model
  RunParam_ls - the one we built while looking for everything
  Run Status (is there a model state and Datastore; what does it think is the status?)
  Could include "live status" if the stage is running in a separate process

Have the ModelStage structure be an "all in one" unit from which we can run a model will greatly
facilitate running models in sub-processes. We pass the ModelStage structure to an R process that
will load visioneval and then run the model using that environment. We could just set up the
ModelStages and work through them. We should always run models that way, and then poll them as they
are running for their status (and keep it all up to date).

TODO: in initializeModel, ignore LoadDatastore and DatastoreName if BaseModel is set in run enviroment

Travel Time Reliability is failing with missing value.

Solve the test_query functionality for output directory by requiring the results to be from "stages" of
the "same" model. So to run multiple directories, we just put them in a folder and then open that folder
as a "staged" model. We'll look at the configuration for each stage to determine which ones to report -
if the stage is loaded by another stage, we drop it from the output list. Then the "output" directory
belongs to the staged model (root folder). Genius!

The test_query function is failing because the output directory is not being created/set right. We want
output to be in ResultsDir, but when we are processing multiple scenarios (or even multiple years for
the same scenario) there is no single ResultsDir - so where then do we put the .csv results?

Look at Tara's/Dave's setup/output for Tableau and make sure we can reproduce it from a VEQuery (reproduce
the specific measures and row/column structure). Also make sure we can generate the tables used
by the existing viewer (with consistent data definitions). Make sure we can generate results
by combining multiple model/result scenarios.

When we start a model, we overlay the physical rosters from the base models into a single virtual
lookup roster that can set the Datastore location group/table/name to retrieve. Writing operations
always go through they "physical" Datastore index (writing into it, deciding whether anything needs
to be overwritten). So the "read" operation is a lookup in two layers - find the Datastore with what
we're looking for, then read it from that location. Writing will update the master table, as well as
the physical index of the local Datastore.

Review Arash's scenario manager.

#) Make several copies of the same base model with different years (only future) and different
   Model Name and Scenario Name.  Then check that we get good output from:
     List of model names
     List of model results
     List of model result directories
#) Add some specifications with the "By" option (income analysis, also by MArea or Azone, and by
   both. See how that shows up in the data.frame of results
#) Test running the same query set at different geographies
#) Think about the API for looking into a "scenario" root directory (where we might probe into
   sub-folders looking for VEResults based on existence of Datastore and ModelState.rda...).
   Eventually all that gets easier with the new VEScenario approach - we'll be able to require
   everything to have the same BaseModel, and a single master ResultsDir for the scenarios.

We should be able to create a list of VEResults (needed for querying) by providing a list
of model names (all in the ModelDir), or a list of ResultsDir folders (how to handle run
steps with that?). Do various diagnostics to figure out what has been supplied. If we provide
a list/vector of names or objects, running the query stuff should assemble all the results
into a single return table (see above).

#) Explore running models in a separate space
   a) Launch an R process that we pre-load with objects from the current process
      Need visioneval, VEModel (full .libPaths); set working directory (ve.runtime)
      and then load/run a particular model. Need to make sure that the whole search
      path is properly constructed (including local environments) and that the
      runtime environment stuff stays loaded. What's the least we could do in a child
      process to make a model run (load VEModel, open the model, run it). Then when
      the process is done, reload the model state (as we currently do) in the front-end
      R session.
#) Get the scenario stuff integrated - very simple set of scenarios
   a) That will be the moment to change the Datastore access, which will need some
      careful thinking about how to initialize (bomb the model initialization if
      the base model has not been run, or should we recursively run the base model?).
      Specify the base model as a VEModel, or just by locating its ResultsDir (both).
   b) Future scenarios just run individual years, not the BaseYear. If there is no BaseModel
      run the BaseYear. Otherwise just run the other explicit years. Models with a BaseModel
      can but should not run the BaseYear.
   c) The key for the scenarios is not to run the BaseYear, which we can easily do just by
      leaving it out of Years.
   d) The BaseModel stuff initially should also encompass the RunScript, and load the
      BaseModel run parameters (so the derived model doesn't need to have any configuration
      other than the InputPath and ResultsDir). If we define Scenarios within the BaseModel
      then we'll just need a set of InputPath elements for each scenario category/level
      that we concatenate into a full set for the Scenario. So the tree could look like:
      /Base-Model
        /inputs
        /defs
        /results
        /queries
        /Scenarios
          /ScenarioName
            ... config files at the root
            ... config files specify category/level plus names
            ... config files also specify the .VEqry that will be applied to generate
                a comparative table of all the scenario results.
            /inputs
              /Category-Level folders with the input files
            /results
              /One subfolder for each permutation of category/level
              /outputs (for queries that run across the full set of results)
   e) Then do the visualizer base on what appears in the 

*) Add a function to clear a query (remove its specs)
*) Check saving and reloading a Query - make sure VEQuerySpec names are reconstructed
*) Do the save/load/save/new versus open at the beginning
*) Improve prettiness of dumped query
*) Get the queries to run on a test model
*) Get queries to run on several models/result sets
*) Format multiple query outputs for use in visualizer / tableau
*) Need the complete set of sample runs for scenario development

API steps:
  - Should be able to clearly distinguish whether VEQuery$new is opening an existing file in
  QueryDir or creating a new one (requiring disambiguated name).
  - Should allow a user-level "load.from" function will load from a file (and put in its
  QueryName if we created the query without it originally.
  - "Create and Load" should be a helper funciton (like "openModel")
  - So we have an "initialize" function that passively sets parameters if provided
  - And we have a "load" function that draws a QuerySpec from a file (and, only if QueryName etc
  are not set, also sets those)

** Need to figure out which 

** Inspector

The inspectModel function should do a very simple interaction:
  1) We launch the HTML viewer, and point it at the page for the kind
     of thing being inspected
  2) Should be able to walk up or down the ladder
  3) Pass to Javascript should be a "Model" or "Collection" (Backbone concepts) with
     a particular name/processing type
  4) Stuff is available

Things we want to inspect:
  1) Settings
    a) Defaults
    b) Global (after ve.runtime)
  2) Models (model directory)
    a) List all models and inspect one
  3) Queries (query directory)
    a) List all queries (root) and inspect one
  4) One Model
    a) List all model stages and inspect one
    b) List all queries for Model (global, model-specific) and inspect one
    c) List Identifier, paths to all result sets for the Model
  5) One Model Stage
    a) Settings
    b) Input Directory (and files present)
    c) Param Dir (and files present)
    d) run_model.R script (raw text)
    e) initializeModel parameters (LoadDatastore)
    f) AllSpecs_ls (ordered sequence of Package/Module/Specs)
        Show Packages
        Within Packages expand to show Modules
        Within Modules expand to show Input, Get, Set specs
        Within a spec
          If Input, show InputDir, File, Group, Table
            Within InputDir,File show Fields, Units, Description
              Expand optionally to remining non-NA spec elements
          If Get/Set
            Show Group/Table
              Within Group, Table show Name, Units, Description
                Expand optionally to remaining non-NA spec elements
  6) One Query
    a) List of Query Specifications (names) and expression, pick one
    b) One Query Specification
       Full list of defined specification elements

Rework the model stage stuff (more thinking about elements and how to navigate)

Separate Datastore locations for RunStep / RunStage (interior auto-generated steps).
Also track Base Model for elements not defined in current mode (virtual Datastore and
locations within it). Retrieval of Group/Table/Name always gets the most recently
written one in the model chain (RunStage / RunStep / Base Model) - there's a Datastore
at the bottom of each such chain. ModelState's Datastore directory contains the location
of the most recently located one within this Datastore (and a link out to the BaseModel
Datastore - we load that up when the model is initialized, expanding on the LoadDatastore
processing that copies the Datastore - we just add a pointer to the ModelState$Datastore
directory for that model, plus its results directory. To access a Datastore for a Base Model,
we just need its ResultsDirectory (location of ModelState plus RunStep/RunStage/Datastore
directory tree; from ModelState, we read Datastore directory)
    
